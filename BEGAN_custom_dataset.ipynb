{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BEGAN_custom_dataset.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/consequencesunintended/BEGAN/blob/main/BEGAN_custom_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9251vKW7YB39"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.engine.topology import Layer\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from IPython import display\n",
        "print (tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IykZGxsJAWl"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Activation, Reshape\n",
        "from tensorflow.keras.layers import Convolution2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Convolution2DTranspose\n",
        "from tensorflow.keras.layers import concatenate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efJxbMwMJAWm"
      },
      "source": [
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Please install GPU version of TF\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm5sXD4nYHsX"
      },
      "source": [
        "DIMENSION = 64\n",
        "noise_dim = 128\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIqUL3dSYK4Z"
      },
      "source": [
        "data_dir = \"data/real/images/*.png\"\n",
        "list_ds = tf.data.Dataset.list_files(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrKtT9z-JAWn"
      },
      "source": [
        "list_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf7Kf8wqCwU8"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcRp0uNYC1hW"
      },
      "source": [
        "for f in list_ds.take(5):\n",
        "    print(f.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ9U-km8C3ku"
      },
      "source": [
        "def decode_img(img):\n",
        "    img = tf.image.decode_png(img, channels=4)\n",
        "    alphas = img[:,:,3:4]\n",
        "    img = img[:,:,:3]\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    alphas = tf.image.convert_image_dtype(alphas, tf.float32)\n",
        "    img = alphas * img\n",
        "    img = tf.image.resize(img, [DIMENSION, DIMENSION])\n",
        "    \n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWCInvghC6lB"
      },
      "source": [
        "def process_path(file_path):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = decode_img(img)\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4DVVYPYC8p0",
        "scrolled": true
      },
      "source": [
        "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnmEha98JAWp"
      },
      "source": [
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "train_dataset_final = labeled_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "train_dataset_final = train_dataset_final.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwO8UX5ODIXC"
      },
      "source": [
        "NUM_IMAGES = len(labeled_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3--2TyrkDgeg"
      },
      "source": [
        "for image in train_dataset_final.take(1):\n",
        "    print(\"Image shape: \", image.numpy().shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSpp81TAYaFz"
      },
      "source": [
        "sample_training_images = next(iter(train_dataset_final))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozkXsYSZJAWq"
      },
      "source": [
        "plt.imshow(sample_training_images[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC-OZ3xzZOXl"
      },
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(DIMENSION,DIMENSION))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img.numpy())          \n",
        "        ax.axis('off')    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I6_WqXCJAWr"
      },
      "source": [
        "plotImages(sample_training_images[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC-mVMUIJAWr"
      },
      "source": [
        "class Resize_nn(Layer):\n",
        "    def __init__(self, image_size=(512, 512), **kwargs):\n",
        "        self.image_size = image_size[0], image_size[1]\n",
        "        super(Resize_nn, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return tf.image.resize(inputs, self.image_size, method='nearest')\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], self.image_size[0], self.image_size[1], input_shape[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6KJnS58JAWr"
      },
      "source": [
        "def decoder():\n",
        "    kernel= 3\n",
        "    filters = 16\n",
        "\n",
        "    inputs = Input(shape=(noise_dim,))\n",
        "    \n",
        "    dense_1 = Dense(8*8*filters)(inputs)\n",
        "    dens_1_reshaped = Reshape([8,8,filters])(dense_1)\n",
        "\n",
        "    conv_1 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(dens_1_reshaped)\n",
        "    conv_1 = tf.nn.elu(conv_1)\n",
        "    \n",
        "    conv_2 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_1)\n",
        "    conv_2 = tf.nn.elu(conv_2)\n",
        "    conv_2 = Resize_nn([DIMENSION//8, DIMENSION//8])(conv_2)\n",
        "    \n",
        "    print(\"decorder-1 DONE!\")\n",
        "    \n",
        "    conv_3 = Convolution2D(2*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_2)\n",
        "    conv_3 = tf.nn.elu(conv_3)\n",
        "    \n",
        "    conv_4 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_3)\n",
        "    conv_4 = tf.nn.elu(conv_4)\n",
        "    conv_4 = Resize_nn([DIMENSION//4, DIMENSION//4])(conv_4)\n",
        "    \n",
        "    print(\"decorder-2 DONE!\")\n",
        "    \n",
        "    conv_4 = Convolution2D(2*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_4)\n",
        "    conv_4 = tf.nn.elu(conv_4)\n",
        "    \n",
        "    conv_5 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_4)\n",
        "    conv_5 = tf.nn.elu(conv_5)\n",
        "    conv_5 = Resize_nn([DIMENSION//2, DIMENSION//2])(conv_5)\n",
        "    \n",
        "    print(\"decorder-3 DONE!\")\n",
        "    \n",
        "    conv_5 = Convolution2D(2*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_5)\n",
        "    conv_5 = tf.nn.elu(conv_5)\n",
        "    \n",
        "    conv_6 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_5)\n",
        "    conv_6 = tf.nn.elu(conv_6)\n",
        "    conv_6 = Resize_nn([DIMENSION, DIMENSION])(conv_6)\n",
        "    \n",
        "    print(\"decorder-4 DONE!\")\n",
        "    \n",
        "    conv_7 = Convolution2D(2*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_6)\n",
        "    conv_7 = tf.nn.elu(conv_7)\n",
        "    \n",
        "    conv_8 = Convolution2D(2*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_7)\n",
        "    conv_8 = tf.nn.elu(conv_8)\n",
        "    \n",
        "    conv_9 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_8)\n",
        "    conv_9 = tf.nn.elu(conv_9)    \n",
        "    \n",
        "    conv_30 = Convolution2D(3, (kernel, kernel), padding=\"same\")(conv_9)\n",
        "    conv_30 = Activation(\"sigmoid\")(conv_30)\n",
        "\n",
        "    outputs = (conv_30)   \n",
        "    \n",
        "    print(\"Decoder Model DONE!\")\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs, name=\"Decoder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7593zzz2JAWt"
      },
      "source": [
        "def encoder():\n",
        "    input_shape = [DIMENSION,DIMENSION,3]\n",
        "    kernel= 3\n",
        "    filters = 16\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    conv_1 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(inputs)\n",
        "    conv_1 = tf.nn.elu(conv_1)\n",
        "    \n",
        "    conv_2 = Convolution2D(2*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_1)\n",
        "    conv_2 = tf.nn.elu(conv_2)\n",
        "    conv_2 = Resize_nn([DIMENSION, DIMENSION])(conv_2)\n",
        "    \n",
        "    print(\"encoder-1 DONE!\")\n",
        "    \n",
        "    conv_3 = Convolution2D(2*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_2)\n",
        "    conv_3 = tf.nn.elu(conv_3)\n",
        "    \n",
        "    conv_4 = Convolution2D(3*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_3)\n",
        "    conv_4 = tf.nn.elu(conv_4)\n",
        "    conv_4 = Resize_nn([DIMENSION//2, DIMENSION//2])(conv_4)\n",
        "    \n",
        "    print(\"encoder-2 DONE!\")\n",
        "    \n",
        "    conv_5 = Convolution2D(3*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_4)\n",
        "    conv_5 = tf.nn.elu(conv_5)\n",
        "    \n",
        "    conv_6 = Convolution2D(3*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_5)\n",
        "    conv_6 = tf.nn.elu(conv_6)\n",
        "    conv_6 = Resize_nn([DIMENSION//4, DIMENSION//4])(conv_6)\n",
        "    \n",
        "    print(\"encoder-3 DONE!\")\n",
        "    \n",
        "    conv_7 = Convolution2D(3*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_6)\n",
        "    conv_7 = tf.nn.elu(conv_7)\n",
        "    \n",
        "    conv_8 = Convolution2D(3*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(conv_7)\n",
        "    conv_8 = tf.nn.elu(conv_8)\n",
        "    conv_8 = Resize_nn([DIMENSION//8, DIMENSION//8])(conv_8)\n",
        "    \n",
        "    conv_8_flatten  = Flatten()(conv_8)\n",
        "    dense_1 = Dense(8*8*3*filters)(conv_8_flatten)\n",
        "    dense_2 = Dense(noise_dim)(dense_1)\n",
        "\n",
        "    outputs = (dense_2)   \n",
        "    \n",
        "    print(\"Encoder Model DONE!\")\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs, name=\"encoder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHrldnBLJAWu"
      },
      "source": [
        "np.unique(sample_training_images[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjjRzChOJAWu"
      },
      "source": [
        "sample_training_images[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eqYgUcGZQoN"
      },
      "source": [
        "def make_generator_model():\n",
        "    \n",
        "    d_model = decoder()\n",
        "    \n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(d_model)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhT23po3JAWv"
      },
      "source": [
        "generator = make_generator_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnLO9MQHJAWv"
      },
      "source": [
        "plt.imshow(sample_training_images[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq5JtKsyZSqj"
      },
      "source": [
        "input_images = tf.random.normal([1, noise_dim])\n",
        "generated_image = generator(input_images, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ9B7DFWZUKG"
      },
      "source": [
        "def make_discriminator_model():\n",
        "    \n",
        "    e_model = encoder()\n",
        "    d_model = decoder()\n",
        "    \n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(e_model)\n",
        "    model.add(d_model)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQfVloBPZWSb"
      },
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLI5CNM9JAWw"
      },
      "source": [
        "def began_autoencoder_loss(out, inp):\n",
        "    \n",
        "    diff = tf.abs(out - inp)\n",
        "    \n",
        "    return tf.reduce_mean(diff)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7sDZUl4JAWw"
      },
      "source": [
        "def get_loss_values(k_t, gamma, D_real_in, D_real_out, D_gen_in, D_gen_out):\n",
        "    mu_real = began_autoencoder_loss(D_real_out, D_real_in)\n",
        "    mu_gen = began_autoencoder_loss(D_gen_out, D_gen_in)\n",
        "    \n",
        "    D_loss = mu_real - k_t * mu_gen\n",
        "    G_loss = mu_gen\n",
        "    \n",
        "    lambda_v = 0.001\n",
        "    k_tp = k_t + lambda_v * (gamma * mu_real - mu_gen)\n",
        "    \n",
        "    convergence_measure = mu_real + np.abs(gamma * mu_real - mu_gen)\n",
        "    \n",
        "    \n",
        "    return G_loss, D_loss, k_tp, convergence_measure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fiBmw-mZcgg"
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4,)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wfbGdkdZeEo"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7GnY6P_Zf1h"
      },
      "source": [
        "num_examples_to_generate = 16\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdPXW8BrZh6y"
      },
      "source": [
        "def train_step(k_t, images):\n",
        "\n",
        "    D_gen_in = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "    D_real_in = images\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(D_gen_in, training=True)\n",
        "\n",
        "        d_generated_images = discriminator(generated_images, training=True)\n",
        "        discrimanted_images = discriminator(D_real_in, training=True)\n",
        "        \n",
        "        gamma = 0.75\n",
        "        gen_loss, disc_loss, k_t, convergence_measure = get_loss_values(k_t, gamma, D_real_in, discrimanted_images, generated_images, d_generated_images)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)    \n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    \n",
        "\n",
        "    return gen_loss, disc_loss, k_t, convergence_measure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaJk2q2hZuD7"
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(predictions[i, :, :] )\n",
        "            \n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8YH9c0CZwZD"
      },
      "source": [
        "STEP_SIZE = NUM_IMAGES // BATCH_SIZE\n",
        "def train(epochs):\n",
        "    k_t = 0.0\n",
        "    step = 0\n",
        "    convergence_measure = 0.0\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        \n",
        "        g_loss = 0\n",
        "        d_loss = 0\n",
        "\n",
        "        for _ in range(STEP_SIZE):\n",
        "            g_loss, d_loss, k_t, convergence_measure = train_step(min(max(k_t, 0.0), 1.0), next(iter(train_dataset_final)))\n",
        "            step += 1\n",
        "            \n",
        "            if ( step % 100 == 0 ):\n",
        "                display.clear_output(wait=True)\n",
        "                print( 'Generator loss:{} Discrimantor loss:{} Convergence:{} K_t:{} step: {}'.format(g_loss, d_loss, convergence_measure, k_t, step))\n",
        "\n",
        "                generate_and_save_images(generator,\n",
        "                         epoch + 1,\n",
        "                         seed)\n",
        "                \n",
        "        display.clear_output(wait=True)\n",
        "\n",
        "        print( 'Generator loss:{} Discrimantor loss:{} Convergence:{} K_t:{} step: {}'.format(g_loss, d_loss, convergence_measure, k_t, step))\n",
        "        generate_and_save_images(generator,\n",
        "                                 epoch + 1,\n",
        "                                 seed)\n",
        "\n",
        "        if (epoch + 1) % 15 == 0:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1duhsfziJAWy"
      },
      "source": [
        "generate_and_save_images(generator, 0, seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJNQT51KZyL3"
      },
      "source": [
        "%%time\n",
        "train(EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrhBstw6Z_3a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}